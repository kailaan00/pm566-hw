---
title: "hw01"
author: "Kaila An"
date: "`r Sys.Date()`"
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r install-libraries}
library(tidyverse)
library(data.table)
library(dplyr)
library(ggplot2)
```

## Step 1. Given the formulated question from the assignment description, you will now conduct EDA Checklist items 2-4. 


First, download 2004 and 2019 data for all sites in California from the EPA Air Quality Data website. Read in the data using data.table(). 

```{r}
data04 <- data.table::fread("ad_viz_plotval_2004_data.csv")
data19 <- data.table::fread("ad_viz_plotval_2019_data.csv")
```


For each of the two datasets, check the dimensions, headers, footers, variable names and variable types.
```{r dimensions}
dim(data04)
dim(data19)
```

```{r headers}
head(data04)
head(data19)
```

```{r footers}
tail(data04)
tail(data19)
```

```{r variable names/types}
str(data04)
str(data19)
```


Check for any data issues, particularly in the key variable we are analyzing. 

```{r daily mean 2004}
summary(data04$`Daily Mean PM2.5 Concentration`)
```

```{r daily mean 2019}
summary(data19$`Daily Mean PM2.5 Concentration`)
```


Make sure you write up a summary of all of your findings.

Based on the findings, we now know that for the 2004 data set, there are 19233 rows and 20 columns, and therefore, 20 different variables that were being recorded.  The variable that we are most concerned with, in this case is the daily mean of PM 2.5 Concentration, in which for 2004, it was 13.12.  The minimum was -0.10, the maximum was 251.00, and the median was 10.10.  On the other hand, for 2019, there were 53156 rows and 20 columns, meaning that the same variables were recorded, but there were more observations/entries at this time.  The daily mean of PM 2.5 concentration for 2019 was 7.738, the minimum was -2.200, the maximum was 120.900, and the median was 6.500.


## Step 2. Combine the two years of data into one data frame. Use the Date variable to create a new column for year, which will serve as an identifier. Change the names of the key variables so that they are easier to refer to in your code.

```{r combine data into 1 frame with new column}
library(dplyr)
data04[ , year:=2004]
data19[ , year:=2019]
data <- rbind(data04, data19)
head(data)
tail(data)
```


```{r rename key variables}
data <- rename(data, PM2.5 = 'Daily Mean PM2.5 Concentration')
```


## Step 3. Create a basic map in leaflet() that shows the locations of the sites (make sure to use different colors for each year). Summarize the spatial distribution of the monitoring sites.

```{r}

```


## Step 4. Check for any missing or implausible values of PM2.5 in the combined dataset. Explore the proportions of each and provide a summary of any temporal patterns you see in these observations.

```{r}
mean(is.na(data$PM2.5))
mean(data$PM2.5<0)
```

We do not have any missing data/values in the set (which the first 0 notates).  The value of 0.0039 can be attributed to the presence of negative values in the set, which are therefore, implausible.  


## Step 5. Explore the main question of interest at three different spatial levels. Create exploratory plots (e.g. boxplots, histograms, line plots) and summary statistics that best suit each level of data. Be sure to write up explanations of what you observe in these data.

# State

# County

# Site in Los Angeles

```{r boxplot}
library(ggplot2)
qplot(year, log2(PM2.5), data = data, geom = "boxplot")
```




